import io
import numpy as np
from scipy.signal import butter, lfilter
from pydub import AudioSegment, effects
import wave
import numpy as np
import scipy.signal as signal
import soundfile as sf
import random

def one_band_eq(wav_bytes: bytes, filter_width: float, filter_freq: float, gain: float) -> bytes:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–æ–ª–æ—Å–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä –∏–ª–∏ —É—Å–∏–ª–∏–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –≤ WAV-—Ñ–∞–π–ª–µ.

    :param wav_bytes: –ë–∞–π—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ WAV-—Ñ–∞–π–ª–∞.
    :param filter_width: –®–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ (–≤ –ì—Ü).
    :param filter_freq: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ —Ñ–∏–ª—å—Ç—Ä–∞ (–≤ –ì—Ü).
    :param gain: –£—Å–∏–ª–µ–Ω–∏–µ/–æ—Å–ª–∞–±–ª–µ–Ω–∏–µ.
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª –≤ –≤–∏–¥–µ –±–∞–π—Ç–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏.
    """
    # –ß—Ç–µ–Ω–∏–µ WAV-—Ñ–∞–π–ª–∞
    with wave.open(io.BytesIO(wav_bytes), 'rb') as wav_in:
        params = wav_in.getparams()
        nchannels, sampwidth, framerate, nframes = params[:4]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —à–∏—Ä–∏–Ω–∞ —Å—ç–º–ø–ª–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–∂–∏–¥–∞–Ω–∏—è–º–∏ (4 –±–∞–π—Ç–∞ = 32 –±–∏—Ç–∞)
        if sampwidth != 4:
            raise ValueError("–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 32-–±–∏—Ç–Ω—ã–µ WAV —Ñ–∞–π–ª—ã.")

        # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ –≤ numpy –º–∞—Å—Å–∏–≤
        audio_data = np.frombuffer(wav_in.readframes(nframes), dtype=np.int32)

        # –ï—Å–ª–∏ —Å—Ç–µ—Ä–µ–æ, –¥–µ–ª–∞–µ–º reshape –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤
        if nchannels == 2:
            audio_data = audio_data.reshape(-1, 2)
    if gain > 0:
        processed_data = bandpass_gain(audio_data, filter_freq, filter_width, gain, framerate)
    else:
        processed_data = bandstop_filter(audio_data, filter_freq, filter_width, framerate)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ WAV-–±–∞–π—Ç—ã
    output_io = io.BytesIO()
    with wave.open(output_io, 'wb') as wav_out:
        wav_out.setparams(params)
        # –£–ø–ª–æ—â–∞–µ–º –º–∞—Å—Å–∏–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –æ–Ω –º–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω—ã–π
        wav_out.writeframes(processed_data.astype(np.int32).tobytes())  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ int32 –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é

    return output_io.getvalue()

def bandpass_gain(audio_data: np.ndarray, central_freq: float, bandwidth: float, gain_dB: float, samp_rate: int) -> np.ndarray:
    """
    –£—Å–∏–ª–∏–≤–∞–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–ª–æ—Å—É —á–∞—Å—Ç–æ—Ç –≤ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–µ, –∫–∞–∫ –≤ —ç–∫–≤–∞–ª–∞–π–∑–µ—Ä–µ.
    
    :param audio_data: numpy –º–∞—Å—Å–∏–≤ —Å –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º–∏ (int32, –¥–≤—É—Ö–∫–∞–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª).
    :param central_freq: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –ø–æ–ª–æ—Å—ã –ø—Ä–æ–ø—É—Å–∫–∞–Ω–∏—è –≤ –ì—Ü.
    :param bandwidth: –®–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å—ã —á–∞—Å—Ç–æ—Ç –≤ –ì—Ü.
    :param gain_dB: –£—Å–∏–ª–µ–Ω–∏–µ/–æ—Å–ª–∞–±–ª–µ–Ω–∏–µ –≤ –¥–µ—Ü–∏–±–µ–ª–∞—Ö (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –¥–ª—è –æ—Å–ª–∞–±–ª–µ–Ω–∏—è).
    :param samp_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (samples per second) –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.
    :return: numpy –º–∞—Å—Å–∏–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–æ–º (—Å –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–π –ø–æ–ª–æ—Å–æ–π —á–∞—Å—Ç–æ—Ç).
    """
    # –ü—Ä–æ–µ–∫—Ç–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞ –¥–ª—è –ø–æ–ª–æ—Å—ã –ø—Ä–æ–ø—É—Å–∫–∞–Ω–∏—è
    lowcut = central_freq - bandwidth / 2
    highcut = central_freq + bandwidth / 2

    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞
    b, a = butter(3, [lowcut / (0.5 * samp_rate), highcut / (0.5 * samp_rate)], btype='bandpass')
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –∫ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º (–ø–æ –æ—Å–∏ 0, —Ç–∞–∫ –∫–∞–∫ –∫–∞–Ω–∞–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω—ã–µ)
    filtered_audio = lfilter(b, a, audio_data, axis=0)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —É—Å–∏–ª–µ–Ω–∏–µ –∏–∑ –¥–µ—Ü–∏–±–µ–ª –≤ –ª–∏–Ω–µ–π–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
    gain = 10 ** (gain_dB / 20)

    # –£—Å–∏–ª–∏–≤–∞–µ–º –∏–ª–∏ –æ—Å–ª–∞–±–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
    filtered_audio_with_gain = filtered_audio * gain

    # –û—Å—Ç–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ (–≤–Ω–µ –ø–æ–ª–æ—Å—ã —á–∞—Å—Ç–æ—Ç) –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É—Å–∏–ª–µ–Ω–Ω—É—é –ø–æ–ª–æ—Å—É —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º —Å–∏–≥–Ω–∞–ª–æ–º
    output_audio = audio_data + (filtered_audio_with_gain - filtered_audio)

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
    max_val = np.iinfo(np.int32).max
    min_val = np.iinfo(np.int32).min
    output_audio = np.clip(output_audio, min_val, max_val)

    # –ü—Ä–∏–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ –∫ —Ç–∏–ø—É int32
    output_audio = output_audio.astype(np.int32)

    return output_audio

def bandstop_filter(audio_data: np.ndarray, central_freq: float, bandwidth: float, samp_rate: int) -> np.ndarray:
    """
    –û—Å–ª–∞–±–ª—è–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–ª–æ—Å—É —á–∞—Å—Ç–æ—Ç –≤ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º bandstop —Ñ–∏–ª—å—Ç—Ä–∞.
    
    :param audio_data: numpy –º–∞—Å—Å–∏–≤ —Å –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º–∏ (int32, –¥–≤—É—Ö–∫–∞–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª).
    :param central_freq: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –ø–æ–ª–æ—Å—ã –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –≤ –ì—Ü.
    :param bandwidth: –®–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å—ã —á–∞—Å—Ç–æ—Ç –≤ –ì—Ü.
    :param samp_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (samples per second) –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.
    :return: numpy –º–∞—Å—Å–∏–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–æ–º —Å –ø–æ–¥–∞–≤–ª–µ–Ω–Ω–æ–π –ø–æ–ª–æ—Å–æ–π —á–∞—Å—Ç–æ—Ç.
    """
    # –†–∞—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç —Å—Ä–µ–∑–∞ –¥–ª—è bandstop
    lowcut = central_freq - bandwidth / 2
    highcut = central_freq + bandwidth / 2

    # –ü—Ä–æ–µ–∫—Ç–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞ —Ç–∏–ø–∞ bandstop
    b, a = butter(3, [lowcut / (0.5 * samp_rate), highcut / (0.5 * samp_rate)], btype='bandstop')
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –∫ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º (–ø–æ –æ—Å–∏ 0, —Ç–∞–∫ –∫–∞–∫ –∫–∞–Ω–∞–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω—ã–µ)
    filtered_audio = lfilter(b, a, audio_data, axis=0)

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
    max_val = np.iinfo(np.int32).max
    min_val = np.iinfo(np.int32).min
    output_audio = np.clip(filtered_audio, min_val, max_val)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
    return output_audio.astype(np.int32)

def normalize_wav_bytes(wav_bytes: bytes, target_dBFS=-14.0) -> bytes:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≥—Ä–æ–º–∫–æ—Å—Ç—å WAV-—Ñ–∞–π–ª–∞.

    :param wav_bytes: WAV-—Ñ–∞–π–ª –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ –±–∞–π—Ç–æ–≤.
    :param target_dBFS: –¶–µ–ª–µ–≤–æ–π —É—Ä–æ–≤–µ–Ω—å –≥—Ä–æ–º–∫–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é -14 –¥–ë).
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ –±–∞–π—Ç–æ–≤.
    """
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –∞—É–¥–∏–æ—Å–µ–≥–º–µ–Ω—Ç–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –±–∞–π—Ç–æ–≤
        audio = AudioSegment.from_file(io.BytesIO(wav_bytes), format="wav")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        change_in_dBFS = target_dBFS - audio.dBFS
        normalized_audio = audio.apply_gain(change_in_dBFS)

        # –≠–∫—Å–ø–æ—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ –≤ —Å—Ç—Ä–æ–∫—É –±–∞–π—Ç–æ–≤
        output_io = io.BytesIO()
        normalized_audio.export(output_io, format="wav")
        return output_io.getvalue()

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {e}")
        return None

def bytes_to_audiosegment(audio_bytes: bytes) -> AudioSegment:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±–∞–π—Ç—ã –≤ –æ–±—ä–µ–∫—Ç AudioSegment"""
    return AudioSegment.from_file(io.BytesIO(audio_bytes), format="wav")

def audiosegment_to_bytes(audio: AudioSegment) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç AudioSegment –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–π—Ç—ã"""
    buffer = io.BytesIO()
    audio.export(buffer, format="wav")
    return buffer.getvalue()

# üé∂ 1. –†–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏—è (Reverb)
def apply_reverb(audio_bytes: bytes, decay: float = 0.4, delay_ms: int = 50) -> bytes:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç —Ä–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏–∏ (Reverb) –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param audio_bytes: –ë–∞–π—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (WAV)
    :param decay: –°—Ç–µ–ø–µ–Ω—å –∑–∞—Ç—É—Ö–∞–Ω–∏—è (0.2-0.8), —á–µ–º –≤—ã—à–µ, —Ç–µ–º –±–æ–ª—å—à–µ —ç—Ö–æ.
    :param delay_ms: –ó–∞–¥–µ—Ä–∂–∫–∞ –æ—Ç—Ä–∞–∂–µ–Ω–∏—è (10-100 –º—Å), –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –ø–æ–º–µ—â–µ–Ω–∏—è.
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –±–∞–π—Ç–∞—Ö
    """
    audio = bytes_to_audiosegment(audio_bytes)
    frame_rate = audio.frame_rate
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –∏–∑ –º—Å –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤
    delay_samples = int(frame_rate * delay_ms / 1000)

    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ –¥–ª—è –æ—Ç—Ä–∞–∂–µ–Ω–∏–π
    reverb_samples = np.zeros(len(samples) + delay_samples * 10)  # 10 –æ—Ç—Ä–∞–∂–µ–Ω–∏–π

    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª
    reverb_samples[:len(samples)] += samples

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞—Ç—É—Ö–∞—é—â–∏–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏—è
    for i in range(1, 10):
        reverb_samples[i * delay_samples:i * delay_samples + len(samples)] += samples * (decay ** i)

    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
    reverb_samples = reverb_samples[:len(samples)]

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    max_value = np.iinfo(np.int32).max
    reverb_samples = np.clip(reverb_samples, -max_value, max_value).astype(np.int32)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ
    processed_audio = audio._spawn(reverb_samples.tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 2. –î–∏–ª–µ–π (Delay)
def apply_delay(audio_bytes: bytes, delay_ms: int = 300, decay: float = 0.5) -> bytes:
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–∞–π—Ç—ã –≤ –æ–±—ä–µ–∫—Ç AudioSegment
    audio = bytes_to_audiosegment(audio_bytes)
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—ç–º–ø–ª–æ–≤ –¥–ª—è –∑–∞–¥–µ—Ä–∂–∫–∏
    delay_samples = int(audio.frame_rate * delay_ms / 1000)
    # –ü–æ–ª—É—á–∞–µ–º —Å—ç–º–ø–ª—ã –∞—É–¥–∏–æ –∫–∞–∫ –º–∞—Å—Å–∏–≤
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32) 
    # –°–æ–∑–¥–∞–µ–º –º–∞—Å—Å–∏–≤ –¥–ª—è –∑–∞–¥–µ—Ä–∂–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    delayed_samples = np.zeros(len(samples) + delay_samples)
    # –ö–æ–ø–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—ç–º–ø–ª—ã –≤ –Ω–∞—á–∞–ª–æ
    delayed_samples[:len(samples)] = samples
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—ç–º–ø–ª—ã —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π —Å —É—á–µ—Ç–æ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∑–∞—Ç—É—Ö–∞–Ω–∏—è
    delayed_samples[delay_samples:] += samples * decay
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å—ç–º–ø–ª—ã –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è 16-–±–∏—Ç–Ω—ã—Ö –∞—É–¥–∏–æ—Ñ–æ—Ä–º–∞—Ç–æ–≤
    max_value = np.iinfo(np.int32).max
    delayed_samples = np.clip(delayed_samples, -max_value, max_value)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—ç–º–ø–ª—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    processed_samples = delayed_samples.astype(np.int32)
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç AudioSegment –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    processed_audio = audio._spawn(processed_samples.tobytes())
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∞—É–¥–∏–æ –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–π—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
    return audiosegment_to_bytes(processed_audio)

# üé∂ 3. –°–∞—Ç—É—Ä–∞—Ü–∏—è (Saturation) ‚Äì –º—è–≥–∫–æ–µ –∞–Ω–∞–ª–æ–≥–æ–≤–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ
def apply_saturation(audio_bytes: bytes, amount: float = 0.5) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    max_value = np.iinfo(np.int32).max  # –î–ª—è 32-–±–∏—Ç–Ω–æ–≥–æ –∞—É–¥–∏–æ
    samples /= max_value

    processed_samples = np.tanh(samples * amount)  # –°–∞—Ç—É—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–∞–Ω–≥–µ–Ω—Å
    saturated_samples = (processed_samples * np.iinfo(audio.array_type).max).astype(audio.array_type)

    samples *= max_value
    saturated_samples = np.clip(saturated_samples, -max_value, max_value)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—ç–º–ø–ª—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    processed_samples = saturated_samples.astype(np.int32)
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç AudioSegment –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    processed_audio = audio._spawn(processed_samples.tobytes())
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∞—É–¥–∏–æ –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–π—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
    return audiosegment_to_bytes(processed_audio)

def apply_distortion(audio_bytes: bytes, gain: float = 10) -> bytes:
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–∞–π—Ç—ã –≤ –æ–±—ä–µ–∫—Ç AudioSegment
    audio = bytes_to_audiosegment(audio_bytes)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å—ç–º–ø–ª—ã –∞—É–¥–∏–æ –∫–∞–∫ –º–∞—Å—Å–∏–≤
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)

    max_value = np.iinfo(np.int32).max  # –î–ª—è 32-–±–∏—Ç–Ω–æ–≥–æ –∞—É–¥–∏–æ

    samples /= max_value
    #
    ## –ü—Ä–∏–º–µ–Ω—è–µ–º —É—Å–∏–ª–µ–Ω–∏–µ (–≥–µ–π–Ω)
    samples *= gain
    #print(samples)
    ## –ü—Ä–∏–º–µ–Ω—è–µ–º –∂–µ—Å—Ç–∫–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∞ (–æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-1, 1])
    samples = np.clip(samples, -1, 1)
    samples *= max_value
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—ç–º–ø–ª—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –º–∞–∫—Å–∏–º—É–º–∞ –¥–ª—è 32-–±–∏—Ç–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
    distorted_samples = np.clip(samples, -max_value, max_value)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—ç–º–ø–ª—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    processed_samples = distorted_samples.astype(np.int32)
    
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç AudioSegment –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    processed_audio = audio._spawn(processed_samples.tobytes())
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞—É–¥–∏–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –±–∞–π—Ç–æ–≤
    return audiosegment_to_bytes(processed_audio)

# üé∂ 5. –ö–æ–º–ø—Ä–µ—Å—Å–∏—è (Compression)
def apply_compression(audio_bytes: bytes, threshold: float = -20, ratio: float = 4) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    compressed_audio = effects.compress_dynamic_range(audio, threshold=threshold, ratio=ratio)
    return audiosegment_to_bytes(compressed_audio)

# üé∂ 6. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –•–æ—Ä—É—Å (Chorus)
def apply_chorus(audio_bytes: bytes, rate_hz: float = 1.5, depth_ms: int = 25) -> bytes:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç —Ö–æ—Ä—É—Å (chorus) –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param audio_bytes: –ë–∞–π—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (WAV)
    :param rate_hz: –ß–∞—Å—Ç–æ—Ç–∞ –º–æ–¥—É–ª—è—Ü–∏–∏ –∑–∞–¥–µ—Ä–∂–∫–∏ (0.5 - 3 –ì—Ü)
    :param depth_ms: –ì–ª—É–±–∏–Ω–∞ –º–æ–¥—É–ª—è—Ü–∏–∏ –∑–∞–¥–µ—Ä–∂–∫–∏ (–æ–±—ã—á–Ω–æ 20-30 –º—Å)
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –±–∞–π—Ç–∞—Ö
    """
    audio = bytes_to_audiosegment(audio_bytes)
    frame_rate = audio.frame_rate
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–¥–µ—Ä–∂–∫—É –≤ —Å—ç–º–ø–ª—ã
    max_delay_samples = int((depth_ms / 1000) * frame_rate)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª –º–æ–¥—É–ª—è—Ü–∏–∏ (—Å–∏–Ω—É—Å–æ–∏–¥–∞–ª—å–Ω—ã–π LFO)
    time = np.arange(len(samples))
    lfo = np.sin(2 * np.pi * rate_hz * time / frame_rate)  # LFO-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä (–º–æ–¥—É–ª–∏—Ä—É–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É)

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–º–µ–Ω—è—é—â—É—é—Å—è –∑–∞–¥–µ—Ä–∂–∫—É (LFO –∏–∑–º–µ–Ω—è–µ—Ç –≤—Ä–µ–º—è –∑–∞–¥–µ—Ä–∂–∫–∏)
    modulated_delay = ((lfo + 1) / 2) * max_delay_samples  # –î–∏–∞–ø–∞–∑–æ–Ω: [0, max_delay_samples]

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π –º–∞—Å—Å–∏–≤ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
    delayed_samples = np.zeros_like(samples)
    for i in range(len(samples)):
        delay = int(modulated_delay[i])  # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é –∑–∞–¥–µ—Ä–∂–∫—É –≤ —Å—ç–º–ø–ª–∞—Ö
        if i - delay >= 0:
            delayed_samples[i] = samples[i - delay]  # –ó–∞–¥–µ—Ä–∂–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª

    # –°–º–µ—à–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ –∑–∞–¥–µ—Ä–∂–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª (50/50)
    chorus_samples = (samples + delayed_samples) / 2

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π
    max_value = np.iinfo(np.int32).max
    chorus_samples = np.clip(chorus_samples, -max_value, max_value).astype(np.int32)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ
    processed_audio = audio._spawn(chorus_samples.tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 7. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –§–ª—ç–Ω–¥–∂–µ—Ä (Flanger)
def apply_flanger(audio_bytes: bytes, rate_hz: float = 0.5, depth_ms: int = 10, feedback: float = 0.5) -> bytes:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç —Ñ–ª—ç–Ω–¥–∂–µ—Ä (flanger) –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param audio_bytes: –ë–∞–π—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (WAV)
    :param rate_hz: –ß–∞—Å—Ç–æ—Ç–∞ –º–æ–¥—É–ª—è—Ü–∏–∏ –∑–∞–¥–µ—Ä–∂–∫–∏ (0.1 - 3 –ì—Ü)
    :param depth_ms: –ì–ª—É–±–∏–Ω–∞ –º–æ–¥—É–ª—è—Ü–∏–∏ –∑–∞–¥–µ—Ä–∂–∫–∏ (–æ–±—ã—á–Ω–æ 5-15 –º—Å)
    :param feedback: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ (0 - –±–µ–∑ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏, 1 - —Å–∏–ª—å–Ω—ã–π —Ä–µ–∑–æ–Ω–∞–Ω—Å)
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –±–∞–π—Ç–∞—Ö
    """
    audio = bytes_to_audiosegment(audio_bytes)
    frame_rate = audio.frame_rate
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≥–ª—É–±–∏–Ω—É –∑–∞–¥–µ—Ä–∂–∫–∏ –≤ —Å—ç–º–ø–ª—ã
    max_delay_samples = int((depth_ms / 1000) * frame_rate)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª –º–æ–¥—É–ª—è—Ü–∏–∏ (LFO) –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏
    time = np.arange(len(samples))
    lfo = np.sin(2 * np.pi * rate_hz * time / frame_rate)  # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –Ω–∏–∑–∫–æ–π —á–∞—Å—Ç–æ—Ç—ã

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–∑–º–µ–Ω—è—é—â—É—é—Å—è –∑–∞–¥–µ—Ä–∂–∫—É (LFO –∏–∑–º–µ–Ω—è–µ—Ç –≤—Ä–µ–º—è –∑–∞–¥–µ—Ä–∂–∫–∏)
    modulated_delay = ((lfo + 1) / 2) * max_delay_samples  # –î–∏–∞–ø–∞–∑–æ–Ω: [0, max_delay_samples]

    # –°–æ–∑–¥–∞—ë–º –º–∞—Å—Å–∏–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    delayed_samples = np.zeros_like(samples)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –∏ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
    for i in range(len(samples)):
        delay = int(modulated_delay[i])  # –¢–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –≤ —Å—ç–º–ø–ª–∞—Ö
        if i - delay >= 0:
            delayed_samples[i] = samples[i - delay] + delayed_samples[i - delay] * feedback  # –ó–∞–¥–µ—Ä–∂–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é

    # –°–º–µ—à–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ –∑–∞–¥–µ—Ä–∂–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
    flanger_samples = (samples + delayed_samples) / 2

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π
    max_value = np.iinfo(np.int32).max
    flanger_samples = np.clip(flanger_samples, -max_value, max_value).astype(np.int32)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ
    processed_audio = audio._spawn(flanger_samples.tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 8. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –¢—Ä–µ–º–æ–ª–æ –ø–æ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
def apply_tremolo(audio_bytes: bytes, rate_hz: float = 5, depth: float = 0.5) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    mod_signal = 1 - (depth * (1 + np.sin(2 * np.pi * np.arange(len(samples)) * rate_hz / audio.frame_rate)) / 2)
    tremolo_samples = samples * mod_signal

    max_value = np.iinfo(np.int32).max
    tremolo_samples = np.clip(tremolo_samples, -max_value, max_value)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—ç–º–ø–ª—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    processed_samples = tremolo_samples.astype(np.int32)
    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç AudioSegment –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—ç–º–ø–ª–æ–≤
    processed_audio = audio._spawn(processed_samples.tobytes())
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∞—É–¥–∏–æ –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–π—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
    return audiosegment_to_bytes(processed_audio)

# üé∂ 9. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –¢—Ä–µ–º–æ–ª–æ –ø–æ –≤—ã—Å–æ—Ç–µ (Vibrato)
def apply_vibrato(audio_bytes: bytes, rate_hz: float = 5, depth_semitones: float = 0.5) -> bytes:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç —á–∞—Å—Ç–æ—Ç–Ω–æ–≥–æ –≤–∏–±—Ä–∞—Ç–æ (Frequency Vibrato) –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param audio_bytes: –ë–∞–π—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (WAV)
    :param rate_hz: –ß–∞—Å—Ç–æ—Ç–∞ –º–æ–¥—É–ª—è—Ü–∏–∏ –≤–∏–±—Ä–∞—Ç–æ (3-8 –ì—Ü)
    :param depth_semitones: –ì–ª—É–±–∏–Ω–∞ –º–æ–¥—É–ª—è—Ü–∏–∏ (–æ–±—ã—á–Ω–æ 0.1 - 1.5 –ø–æ–ª—É—Ç–æ–Ω–æ–≤)
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –±–∞–π—Ç–∞—Ö
    """
    audio = bytes_to_audiosegment(audio_bytes)
    frame_rate = audio.frame_rate
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª –º–æ–¥—É–ª—è—Ü–∏–∏ (LFO) –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—ã—Å–æ—Ç—ã –∑–≤—É–∫–∞
    time = np.arange(len(samples))
    vibrato_signal = np.sin(2 * np.pi * rate_hz * time / frame_rate) * depth_semitones

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≥–ª—É–±–∏–Ω—É –º–æ–¥—É–ª—è—Ü–∏–∏ –≤ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã
    pitch_factor = 2 ** (vibrato_signal / 12)  # –ü–µ—Ä–µ–≤–æ–¥ –ø–æ–ª—É—Ç–æ–Ω–æ–≤ –≤ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —á–∞—Å—Ç–æ—Ç—ã

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã —Å –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–µ–π
    indices = np.arange(len(samples)) * pitch_factor
    indices = np.clip(indices, 0, len(samples) - 1)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –∏–Ω–¥–µ–∫—Å–æ–≤
    vibrato_samples = np.interp(indices, np.arange(len(samples)), samples)

    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π
    max_value = np.iinfo(np.int32).max
    vibrato_samples = np.clip(vibrato_samples, -max_value, max_value).astype(np.int32)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –∞—É–¥–∏–æ
    processed_audio = audio._spawn(vibrato_samples.tobytes())
    return audiosegment_to_bytes(processed_audio)

# üéµ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —ç—Ñ—Ñ–µ–∫—Ç–∞ —Å —É—á–µ—Ç–æ–º —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
def apply_random_effect(audio_bytes: bytes, difficulty: str = "medium") -> tuple[bytes, str]:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É —Å —Ä–∞–∑–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏."""
    def apply_no_effect(audio_bytes: bytes) -> bytes:
        return audio_bytes

    difficulty_params = {
        "easy": {
            "reverb_decay": 0.8, "reverb_delay": 100,
            "delay_ms": 500, "delay_decay": 0.7,
            "distortion_gain": 3,
            "tremolo_rate": 5, "tremolo_depth": 0.8,
            "vibrato_rate": 1.0, "vibrato_depth": 0.08,
            "flanger_rate": 0.5, "flanger_depth": 8,
            "chorus_rate": 0.7, "chorus_depth": 7,
            "compression_th": -40, "compression_ratio" : 16,
            "saturation": 3
        },
        "medium": {
            "reverb_decay": 0.6, "reverb_delay": 75,
            "delay_ms": 300, "delay_decay": 0.5,
            "distortion_gain": 2,
            "tremolo_rate": 7, "tremolo_depth": 0.6,
            "vibrato_rate": 0.7, "vibrato_depth": 0.03,
            "flanger_rate": 0.3, "flanger_depth": 5,
            "chorus_rate": 0.5, "chorus_depth": 5,
            "compression_th": -20, "compression_ratio" : 8,
            "saturation": 2
        },
        "hard": {
            "reverb_decay": 0.4, "reverb_delay": 50,
            "delay_ms": 100, "delay_decay": 0.3,
            "distortion_gain": 1.5,
            "tremolo_rate": 10, "tremolo_depth": 0.3,
            "vibrato_rate": 0.5, "vibrato_depth": 0.01,
            "flanger_rate": 0.1, "flanger_depth": 2,
            "chorus_rate": 1, "chorus_depth": 2,
            "compression_th": -10, "compression_ratio" : 4,
            "saturation": 1
        }
    }
    
    params = difficulty_params.get(difficulty, difficulty_params["medium"])
    effects_list = [
        ("Reverb", apply_reverb, [params["reverb_decay"]]), #OK
        ("Delay", apply_delay, [params["delay_ms"], params["delay_decay"]]), #OK
        ("Distortion", apply_distortion, [params["distortion_gain"]]), #OK
        ("Tremolo", apply_tremolo, [params["tremolo_rate"], params["tremolo_depth"]]), #OK
        ("Flanger", apply_flanger, [params["flanger_rate"], params["flanger_depth"]]), #OK
        ("Chorus", apply_chorus, [params["chorus_rate"], params["chorus_depth"]]), #OK
        ("Vibrato", apply_vibrato, [params["vibrato_rate"], params["vibrato_depth"]]), #OK
        ("Compression", apply_compression, [params["compression_th"], params["compression_ratio"]]), #SUPER
        ("Saturation", apply_saturation, [params["saturation"]]), #OK
        ("No effect", apply_no_effect, [])
    ]
    
    effect_name, effect_func, effect_args = random.choice(effects_list)
    
    modified_audio = effect_func(audio_bytes, *effect_args)
    
    return modified_audio, effect_name

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    #with open("D:/–£–Ω–∏–≤–µ—Ä/–î–ò–ü–õ–û–ú/Project/fs/testing_tracks/full-1.wav", "rb") as f:
    #    wav_data = f.read()

    #processed_wav = one_band_eq(wav_data, 145, 150, 10)

    #with open("output.wav", "wb") as f:
    #    f.write(processed_wav)

    with open("D:/–£–Ω–∏–≤–µ—Ä/–î–ò–ü–õ–û–ú/Project/chords.wav", "rb") as f:
        input_audio = f.read()

    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏–∏
    processed_audio = apply_reverb(input_audio, decay=0.4)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    with open("output.wav", "wb") as f:
        f.write(processed_audio)

import io
import numpy as np
from scipy.signal import butter, lfilter
from pydub import AudioSegment, effects
import wave
import numpy as np
import scipy.signal as signal
import soundfile as sf

def one_band_eq(wav_bytes: bytes, filter_width: float, filter_freq: float, gain: float) -> bytes:
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–æ–ª–æ—Å–æ–≤–æ–π —Ñ–∏–ª—å—Ç—Ä –∏–ª–∏ —É—Å–∏–ª–∏–≤–∞–µ—Ç —á–∞—Å—Ç–æ—Ç—ã –≤ WAV-—Ñ–∞–π–ª–µ.

    :param wav_bytes: –ë–∞–π—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ WAV-—Ñ–∞–π–ª–∞.
    :param filter_width: –®–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ (–≤ –ì—Ü).
    :param filter_freq: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ —Ñ–∏–ª—å—Ç—Ä–∞ (–≤ –ì—Ü).
    :param gain: –£—Å–∏–ª–µ–Ω–∏–µ/–æ—Å–ª–∞–±–ª–µ–Ω–∏–µ.
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª –≤ –≤–∏–¥–µ –±–∞–π—Ç–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏.
    """
    # –ß—Ç–µ–Ω–∏–µ WAV-—Ñ–∞–π–ª–∞
    with wave.open(io.BytesIO(wav_bytes), 'rb') as wav_in:
        params = wav_in.getparams()
        nchannels, sampwidth, framerate, nframes = params[:4]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —à–∏—Ä–∏–Ω–∞ —Å—ç–º–ø–ª–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–∂–∏–¥–∞–Ω–∏—è–º–∏ (4 –±–∞–π—Ç–∞ = 32 –±–∏—Ç–∞)
        if sampwidth != 4:
            raise ValueError("–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 32-–±–∏—Ç–Ω—ã–µ WAV —Ñ–∞–π–ª—ã.")

        # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ –≤ numpy –º–∞—Å—Å–∏–≤
        audio_data = np.frombuffer(wav_in.readframes(nframes), dtype=np.int32)

        # –ï—Å–ª–∏ —Å—Ç–µ—Ä–µ–æ, –¥–µ–ª–∞–µ–º reshape –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤
        if nchannels == 2:
            audio_data = audio_data.reshape(-1, 2)
    print(audio_data)
    print(audio_data[0][0].dtype)
    if gain > 0:
        processed_data = bandpass_gain(audio_data, filter_freq, filter_width, gain, framerate)
    else:
        processed_data = bandstop_filter(audio_data, filter_freq, filter_width, framerate)
    print(processed_data)
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–∞—Å—Å–∏–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ WAV-–±–∞–π—Ç—ã
    output_io = io.BytesIO()
    with wave.open(output_io, 'wb') as wav_out:
        wav_out.setparams(params)
        # –£–ø–ª–æ—â–∞–µ–º –º–∞—Å—Å–∏–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏, –µ—Å–ª–∏ –æ–Ω –º–Ω–æ–≥–æ–∫–∞–Ω–∞–ª—å–Ω—ã–π
        wav_out.writeframes(processed_data.astype(np.int32).tobytes())  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ int32 –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é

    return output_io.getvalue()

def bandpass_gain(audio_data: np.ndarray, central_freq: float, bandwidth: float, gain_dB: float, samp_rate: int) -> np.ndarray:
    """
    –£—Å–∏–ª–∏–≤–∞–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–ª–æ—Å—É —á–∞—Å—Ç–æ—Ç –≤ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–µ, –∫–∞–∫ –≤ —ç–∫–≤–∞–ª–∞–π–∑–µ—Ä–µ.
    
    :param audio_data: numpy –º–∞—Å—Å–∏–≤ —Å –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º–∏ (int32, –¥–≤—É—Ö–∫–∞–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª).
    :param central_freq: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –ø–æ–ª–æ—Å—ã –ø—Ä–æ–ø—É—Å–∫–∞–Ω–∏—è –≤ –ì—Ü.
    :param bandwidth: –®–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å—ã —á–∞—Å—Ç–æ—Ç –≤ –ì—Ü.
    :param gain_dB: –£—Å–∏–ª–µ–Ω–∏–µ/–æ—Å–ª–∞–±–ª–µ–Ω–∏–µ –≤ –¥–µ—Ü–∏–±–µ–ª–∞—Ö (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –¥–ª—è –æ—Å–ª–∞–±–ª–µ–Ω–∏—è).
    :param samp_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (samples per second) –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.
    :return: numpy –º–∞—Å—Å–∏–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–æ–º (—Å –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–π –ø–æ–ª–æ—Å–æ–π —á–∞—Å—Ç–æ—Ç).
    """
    # –ü—Ä–æ–µ–∫—Ç–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞ –¥–ª—è –ø–æ–ª–æ—Å—ã –ø—Ä–æ–ø—É—Å–∫–∞–Ω–∏—è
    lowcut = central_freq - bandwidth / 2
    highcut = central_freq + bandwidth / 2

    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞
    b, a = butter(3, [lowcut / (0.5 * samp_rate), highcut / (0.5 * samp_rate)], btype='bandpass')
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –∫ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º (–ø–æ –æ—Å–∏ 0, —Ç–∞–∫ –∫–∞–∫ –∫–∞–Ω–∞–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω—ã–µ)
    filtered_audio = lfilter(b, a, audio_data, axis=0)

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —É—Å–∏–ª–µ–Ω–∏–µ –∏–∑ –¥–µ—Ü–∏–±–µ–ª –≤ –ª–∏–Ω–µ–π–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
    gain = 10 ** (gain_dB / 20)

    # –£—Å–∏–ª–∏–≤–∞–µ–º –∏–ª–∏ –æ—Å–ª–∞–±–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
    filtered_audio_with_gain = filtered_audio * gain

    # –û—Å—Ç–∞–ª—å–Ω–∞—è —á–∞—Å—Ç—å —Å–∏–≥–Ω–∞–ª–∞ (–≤–Ω–µ –ø–æ–ª–æ—Å—ã —á–∞—Å—Ç–æ—Ç) –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É—Å–∏–ª–µ–Ω–Ω—É—é –ø–æ–ª–æ—Å—É —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º —Å–∏–≥–Ω–∞–ª–æ–º
    output_audio = audio_data + (filtered_audio_with_gain - filtered_audio)

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
    max_val = np.iinfo(np.int32).max
    min_val = np.iinfo(np.int32).min
    output_audio = np.clip(output_audio, min_val, max_val)

    # –ü—Ä–∏–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ –∫ —Ç–∏–ø—É int32
    output_audio = output_audio.astype(np.int32)

    return output_audio

def bandstop_filter(audio_data: np.ndarray, central_freq: float, bandwidth: float, samp_rate: int) -> np.ndarray:
    """
    –û—Å–ª–∞–±–ª—è–µ—Ç —É–∫–∞–∑–∞–Ω–Ω—É—é –ø–æ–ª–æ—Å—É —á–∞—Å—Ç–æ—Ç –≤ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º bandstop —Ñ–∏–ª—å—Ç—Ä–∞.
    
    :param audio_data: numpy –º–∞—Å—Å–∏–≤ —Å –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º–∏ (int32, –¥–≤—É—Ö–∫–∞–Ω–∞–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª).
    :param central_freq: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –ø–æ–ª–æ—Å—ã –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –≤ –ì—Ü.
    :param bandwidth: –®–∏—Ä–∏–Ω–∞ –ø–æ–ª–æ—Å—ã —á–∞—Å—Ç–æ—Ç –≤ –ì—Ü.
    :param samp_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (samples per second) –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.
    :return: numpy –º–∞—Å—Å–∏–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª–æ–º —Å –ø–æ–¥–∞–≤–ª–µ–Ω–Ω–æ–π –ø–æ–ª–æ—Å–æ–π —á–∞—Å—Ç–æ—Ç.
    """
    # –†–∞—Å—á–µ—Ç —á–∞—Å—Ç–æ—Ç —Å—Ä–µ–∑–∞ –¥–ª—è bandstop
    lowcut = central_freq - bandwidth / 2
    highcut = central_freq + bandwidth / 2

    # –ü—Ä–æ–µ–∫—Ç–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä –ë–∞—Ç—Ç–µ—Ä–≤–æ—Ä—Ç–∞ —Ç–∏–ø–∞ bandstop
    b, a = butter(3, [lowcut / (0.5 * samp_rate), highcut / (0.5 * samp_rate)], btype='bandstop')
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –∫ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–º (–ø–æ –æ—Å–∏ 0, —Ç–∞–∫ –∫–∞–∫ –∫–∞–Ω–∞–ª—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–Ω—ã–µ)
    filtered_audio = lfilter(b, a, audio_data, axis=0)

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
    max_val = np.iinfo(np.int32).max
    min_val = np.iinfo(np.int32).min
    output_audio = np.clip(filtered_audio, min_val, max_val)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª
    return output_audio.astype(np.int32)

def normalize_wav_bytes(wav_bytes: bytes, target_dBFS=-14.0) -> bytes:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≥—Ä–æ–º–∫–æ—Å—Ç—å WAV-—Ñ–∞–π–ª–∞.

    :param wav_bytes: WAV-—Ñ–∞–π–ª –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ –±–∞–π—Ç–æ–≤.
    :param target_dBFS: –¶–µ–ª–µ–≤–æ–π —É—Ä–æ–≤–µ–Ω—å –≥—Ä–æ–º–∫–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é -14 –¥–ë).
    :return: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π WAV-—Ñ–∞–π–ª –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏ –±–∞–π—Ç–æ–≤.
    """
    try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –∞—É–¥–∏–æ—Å–µ–≥–º–µ–Ω—Ç–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –±–∞–π—Ç–æ–≤
        audio = AudioSegment.from_file(io.BytesIO(wav_bytes), format="wav")

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        change_in_dBFS = target_dBFS - audio.dBFS
        normalized_audio = audio.apply_gain(change_in_dBFS)

        # –≠–∫—Å–ø–æ—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ –≤ —Å—Ç—Ä–æ–∫—É –±–∞–π—Ç–æ–≤
        output_io = io.BytesIO()
        normalized_audio.export(output_io, format="wav")
        return output_io.getvalue()

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—É–¥–∏–æ: {e}")
        return None

def bytes_to_audiosegment(audio_bytes: bytes) -> AudioSegment:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –±–∞–π—Ç—ã –≤ –æ–±—ä–µ–∫—Ç AudioSegment"""
    return AudioSegment.from_file(io.BytesIO(audio_bytes), format="wav")

def audiosegment_to_bytes(audio: AudioSegment) -> bytes:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç AudioSegment –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–π—Ç—ã"""
    buffer = io.BytesIO()
    audio.export(buffer, format="wav")
    return buffer.getvalue()

# üé∂ 1. –†–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏—è (Reverb)
def apply_reverb(audio_bytes: bytes, decay: float = 0.3) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32) / np.iinfo(audio.array_type).max
    reverb_filter = np.exp(-np.linspace(0, decay, len(samples)))
    processed_samples = np.convolve(samples, reverb_filter, mode='same')
    processed_samples = np.clip(processed_samples, -1, 1) * np.iinfo(audio.array_type).max
    processed_audio = audio._spawn(processed_samples.astype(audio.array_type).tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 2. –î–∏–ª–µ–π (Delay)
def apply_delay(audio_bytes: bytes, delay_ms: int = 300, decay: float = 0.5) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    delay_samples = int(audio.frame_rate * delay_ms / 1000)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    delayed_samples = np.zeros(len(samples) + delay_samples)
    delayed_samples[:len(samples)] = samples
    delayed_samples[delay_samples:] += samples * decay
    processed_audio = audio._spawn((delayed_samples[:len(samples)] * np.iinfo(audio.array_type).max).astype(audio.array_type).tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 3. –°–∞—Ç—É—Ä–∞—Ü–∏—è (Saturation) ‚Äì –º—è–≥–∫–æ–µ –∞–Ω–∞–ª–æ–≥–æ–≤–æ–µ –Ω–∞—Å—ã—â–µ–Ω–∏–µ
def apply_saturation(audio_bytes: bytes, amount: float = 0.5) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    processed_samples = np.tanh(samples * amount)  # –°–∞—Ç—É—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ –≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–∞–Ω–≥–µ–Ω—Å
    processed_samples = (processed_samples * np.iinfo(audio.array_type).max).astype(audio.array_type)
    processed_audio = audio._spawn(processed_samples.tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 4. –ü–µ—Ä–µ–≥—Ä—É–∑ (Distortion) ‚Äì –∂–µ—Å—Ç–∫–æ–µ —Ü–∏—Ñ—Ä–æ–≤–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
def apply_distortion(audio_bytes: bytes, gain: float = 10) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32) * gain
    samples = np.clip(samples, -1, 1)  # –ñ–µ—Å—Ç–∫–æ–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–µ—Ä–µ–≥—Ä—É–∑–∞
    processed_samples = (samples * np.iinfo(audio.array_type).max).astype(audio.array_type)
    processed_audio = audio._spawn(processed_samples.tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 5. –ö–æ–º–ø—Ä–µ—Å—Å–∏—è (Compression)
def apply_compression(audio_bytes: bytes, threshold: float = -20, ratio: float = 4) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    compressed_audio = effects.compress_dynamic_range(audio, threshold=threshold, ratio=ratio)
    return audiosegment_to_bytes(compressed_audio)

# üé∂ 6. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –•–æ—Ä—É—Å (Chorus)
def apply_chorus(audio_bytes: bytes, rate_hz: float = 1.5, depth: int = 25) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    mod_signal = np.sin(2 * np.pi * np.arange(len(samples)) * rate_hz / audio.frame_rate) * depth
    modulated_samples = np.interp(np.arange(len(samples)) + mod_signal, np.arange(len(samples)), samples)
    processed_audio = audio._spawn((modulated_samples * np.iinfo(audio.array_type).max).astype(audio.array_type).tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 7. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –§–ª—ç–Ω–¥–∂–µ—Ä (Flanger)
def apply_flanger(audio_bytes: bytes, rate_hz: float = 0.25, depth: int = 5) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    mod_signal = np.sin(2 * np.pi * np.arange(len(samples)) * rate_hz / audio.frame_rate) * depth
    flanged_samples = (samples + np.interp(np.arange(len(samples)) - mod_signal, np.arange(len(samples)), samples)) / 2
    processed_audio = audio._spawn((flanged_samples * np.iinfo(audio.array_type).max).astype(audio.array_type).tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 8. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –¢—Ä–µ–º–æ–ª–æ –ø–æ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
def apply_tremolo(audio_bytes: bytes, rate_hz: float = 5, depth: float = 0.5) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    mod_signal = 1 - (depth * (1 + np.sin(2 * np.pi * np.arange(len(samples)) * rate_hz / audio.frame_rate)) / 2)
    tremolo_samples = samples * mod_signal
    processed_audio = audio._spawn((tremolo_samples * np.iinfo(audio.array_type).max).astype(audio.array_type).tobytes())
    return audiosegment_to_bytes(processed_audio)

# üé∂ 9. –ú–æ–¥—É–ª—è—Ü–∏—è ‚Äì –¢—Ä–µ–º–æ–ª–æ –ø–æ –≤—ã—Å–æ—Ç–µ (Vibrato)
def apply_vibrato(audio_bytes: bytes, rate_hz: float = 5, depth: float = 10) -> bytes:
    audio = bytes_to_audiosegment(audio_bytes)
    samples = np.array(audio.get_array_of_samples(), dtype=np.float32)
    mod_signal = np.sin(2 * np.pi * np.arange(len(samples)) * rate_hz / audio.frame_rate) * depth
    vibrato_samples = np.interp(np.arange(len(samples)) + mod_signal, np.arange(len(samples)), samples)
    processed_audio = audio._spawn((vibrato_samples * np.iinfo(audio.array_type).max).astype(audio.array_type).tobytes())
    return audiosegment_to_bytes(processed_audio)


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    #with open("D:/–£–Ω–∏–≤–µ—Ä/–î–ò–ü–õ–û–ú/Project/fs/testing_tracks/full-1.wav", "rb") as f:
    #    wav_data = f.read()

    #processed_wav = one_band_eq(wav_data, 145, 150, 10)

    #with open("output.wav", "wb") as f:
    #    f.write(processed_wav)

    with open("D:/–£–Ω–∏–≤–µ—Ä/–î–ò–ü–õ–û–ú/Project/chords.wav", "rb") as f:
        input_audio = f.read()

    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–≤–µ—Ä–±–µ—Ä–∞—Ü–∏–∏
    processed_audio = apply_reverb(input_audio, decay=0.4)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    with open("output.wav", "wb") as f:
        f.write(processed_audio)
